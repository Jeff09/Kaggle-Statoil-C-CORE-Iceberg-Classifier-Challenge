{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-25T18:42:51.282543Z",
     "start_time": "2017-12-25T18:42:26.226823Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import StratifiedKFold, StratifiedShuffleSplit\n",
    "from os.path import join as opj\n",
    "import keras\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-25T18:43:13.630430Z",
     "start_time": "2017-12-25T18:42:51.284474Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Load the data.\n",
    "train = pd.read_json(\"data/processed/train.json\")\n",
    "test = pd.read_json(\"data/processed/test.json\")\n",
    "\n",
    "target_train=train['is_iceberg']\n",
    "test['inc_angle']=pd.to_numeric(test['inc_angle'], errors='coerce')\n",
    "train['inc_angle']=pd.to_numeric(train['inc_angle'], errors='coerce')#We have only 133 NAs.\n",
    "train['inc_angle']=train['inc_angle'].fillna(method='pad')\n",
    "X_angle=train['inc_angle']\n",
    "test['inc_angle']=pd.to_numeric(test['inc_angle'], errors='coerce')\n",
    "X_test_angle=test['inc_angle']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-25T18:43:14.317756Z",
     "start_time": "2017-12-25T18:43:13.632909Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Generate the training data\n",
    "X_band_1=np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in train[\"band_1\"]])\n",
    "X_band_2=np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in train[\"band_2\"]])\n",
    "#X_band_3=(X_band_1+X_band_2)/2\n",
    "X_band_3=np.fabs(np.subtract(X_band_1,X_band_2))\n",
    "X_band_4=np.maximum(X_band_1,X_band_2)\n",
    "X_band_5=np.minimum(X_band_1,X_band_2)\n",
    "#X_band_3=np.array([np.full((75, 75), angel).astype(np.float32) for angel in train[\"inc_angle\"]])\n",
    "X_train = np.concatenate([                       \n",
    "                          X_band_3[:, :, :, np.newaxis],X_band_4[:, :, :, np.newaxis],X_band_5[:, :, :, np.newaxis]], axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-25T18:43:18.672268Z",
     "start_time": "2017-12-25T18:43:14.319263Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_band_test_1=np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in test[\"band_1\"]])\n",
    "X_band_test_2=np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in test[\"band_2\"]])\n",
    "#X_band_test_3=(X_band_test_1+X_band_test_2)/2\n",
    "X_band_test_3=np.fabs(np.subtract(X_band_test_1,X_band_test_2))\n",
    "X_band_test_4=np.maximum(X_band_test_1,X_band_test_2)\n",
    "X_band_test_5=np.minimum(X_band_test_1,X_band_test_2)\n",
    "#X_band_test_3=np.array([np.full((75, 75), angel).astype(np.float32) for angel in test[\"inc_angle\"]])\n",
    "X_test = np.concatenate([\n",
    "                          X_band_test_3[:, :, :, np.newaxis], X_band_test_4[:, :, :, np.newaxis],X_band_test_5[:, :, :, np.newaxis]],axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-25T18:43:20.662156Z",
     "start_time": "2017-12-25T18:43:18.673546Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from skimage.transform import resize\n",
    "\n",
    "def resize_images(df, width):\n",
    "    n = len(df)\n",
    "    df_resized = np.zeros((n, width, width, 3), dtype=np.float32)\n",
    "    for i in tqdm(range(n)):\n",
    "        x = df[i]\n",
    "        x = (x-x.min())/(x.max()-x.min()) # normalize for each pseudo pixel value\n",
    "        df_resized[i] = resize(x, (width,width), mode='reflect')\n",
    "    return df_resized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-25T18:44:57.851117Z",
     "start_time": "2017-12-25T18:43:20.663662Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 1604/1604 [00:15<00:00, 103.80it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 8424/8424 [01:21<00:00, 103.09it/s]\n"
     ]
    }
   ],
   "source": [
    "X_train_re = resize_images(X_train, 224)\n",
    "X_test_re = resize_images(X_test, 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-25T18:47:28.042064Z",
     "start_time": "2017-12-25T18:47:28.017499Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "batch_size=32\n",
    "# Define the image transformations here\n",
    "gen = ImageDataGenerator(horizontal_flip = True,\n",
    "                         vertical_flip = True,\n",
    "                         width_shift_range = 0.,\n",
    "                         height_shift_range = 0.,\n",
    "                         channel_shift_range=0,\n",
    "                         zoom_range = 0.5,\n",
    "                         rotation_range = 10)\n",
    "\n",
    "# Here is the function that merges our two generators\n",
    "# We use the exact same generator with the same random seed for both the y and angle arrays\n",
    "def gen_flow_for_two_inputs(X1, X2, y):\n",
    "    genX1 = gen.flow(X1,y,  batch_size=batch_size,seed=55)\n",
    "    genX2 = gen.flow(X1,X2, batch_size=batch_size,seed=55)\n",
    "    while True:\n",
    "            X1i = genX1.next()\n",
    "            X2i = genX2.next()\n",
    "            #Assert arrays are equal - this was for peace of mind, but slows down training\n",
    "            #np.testing.assert_array_equal(X1i[0],X2i[0])\n",
    "            yield [X1i[0], X2i[1]], X1i[1]\n",
    "\n",
    "def gen_flow_for_one_input(X1, y):\n",
    "    genX1 = gen.flow(X1,y,  batch_size=batch_size,seed=666)\n",
    "    while True:\n",
    "            X1i = genX1.next()\n",
    "            #X2i = genX2.next()\n",
    "            #Assert arrays are equal - this was for peace of mind, but slows down training\n",
    "            #np.testing.assert_array_equal(X1i[0],X2i[0])\n",
    "            yield X1i[0], X1i[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-25T18:44:58.008202Z",
     "start_time": "2017-12-25T18:44:57.972429Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot\n",
    "import keras as k\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Lambda, Activation\n",
    "from keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D, GlobalAveragePooling2D,Input\n",
    "from keras.layers import GlobalMaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras.models import Model\n",
    "from keras import initializers\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint, Callback, EarlyStopping, ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-25T18:44:58.101408Z",
     "start_time": "2017-12-25T18:44:58.010209Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ConvBlock(model, layers, filters):\n",
    "    '''Create [layers] layers consisting of zero padding, a convolution with [filters] 3x3 filters and batch normalization. Perform max pooling after the last layer.'''\n",
    "    for i in range(layers):\n",
    "        model.add(ZeroPadding2D((1, 1)))\n",
    "        model.add(Conv2D(filters, (3, 3), activation='relu'))\n",
    "        model.add(BatchNormalization(axis=3))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "def create_model():\n",
    "    '''Create the FCN and return a keras model.'''\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    # Input image: 75x75x3\n",
    "    model.add(Lambda(lambda x: x, input_shape=(75, 75, 3)))\n",
    "    ConvBlock(model, 1, 32)\n",
    "    # 37x37x32\n",
    "    ConvBlock(model, 1, 64)\n",
    "    # 18x18x64\n",
    "    ConvBlock(model, 1, 128)\n",
    "    # 9x9x128\n",
    "    ConvBlock(model, 1, 128)\n",
    "    # 4x4x128\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Conv2D(2, (3, 3), activation='relu'))\n",
    "    model.add(GlobalAveragePooling2D())\n",
    "    # 4x4x2\n",
    "    #model.add(Activation('softmax'))\n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation('sigmoid'))\n",
    "    \n",
    "    mypotim=Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer=mypotim,\n",
    "                  metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-25T18:44:58.180238Z",
     "start_time": "2017-12-25T18:44:58.102915Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.xception import Xception\n",
    "from keras.applications.mobilenet import MobileNet\n",
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.layers import Concatenate, Dense, LSTM, Input, concatenate\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-25T18:44:58.334555Z",
     "start_time": "2017-12-25T18:44:58.183246Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getVggAngleModel():\n",
    "    input_2 = Input(shape=[1], name=\"angle\")\n",
    "    angle_layer = Dense(1, )(input_2)\n",
    "    base_model = VGG16(weights='imagenet', include_top=False, \n",
    "                 input_shape=X_train_re.shape[1:], classes=1)\n",
    "    x = base_model.get_layer('block5_pool').output\n",
    "    x = GlobalMaxPooling2D()(x)\n",
    "    base_model2 = MobileNet(weights=None, alpha=0.9,input_tensor = base_model.input,include_top=False, input_shape=X_train_re.shape[1:])\n",
    "\n",
    "    x2 = base_model2.output\n",
    "    x2 = GlobalAveragePooling2D()(x2)\n",
    "\n",
    "    merge_one = concatenate([x, x2, angle_layer])\n",
    "\n",
    "    merge_one = Dropout(0.6)(merge_one)\n",
    "    predictions = Dense(1, activation='sigmoid',kernel_initializer='he_normal')(merge_one)\n",
    "    \n",
    "    model = Model(input=[base_model.input, input_2], output=predictions)\n",
    "    \n",
    "    sgd = Adam(lr=1e-4) #SGD(lr=1e-4, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer=sgd,\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-25T18:44:58.444279Z",
     "start_time": "2017-12-25T18:44:58.336395Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_callbacks(filepath, patience=2):\n",
    "    es = EarlyStopping('val_loss', patience=patience, mode=\"min\")\n",
    "    reduce_lr_loss = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=7, verbose=1, epsilon=1e-4, mode='min')\n",
    "    msave = ModelCheckpoint(filepath, save_best_only=True)\n",
    "    return [msave,reduce_lr_loss, es]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-25T18:44:58.566862Z",
     "start_time": "2017-12-25T18:44:58.446214Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Using K-fold Cross Validation with Data Augmentation.\n",
    "def myAngleCV(X_train, X_angle, X_test):\n",
    "    K=5\n",
    "    folds = list(StratifiedKFold(n_splits=K, shuffle=True, random_state=16).split(X_train, target_train))\n",
    "    y_test_pred_log = 0\n",
    "    y_train_pred_log=0\n",
    "    y_valid_pred_log = 0.0*target_train\n",
    "    for j, (train_idx, test_idx) in enumerate(folds):\n",
    "        print('\\n===================FOLD=',j)\n",
    "        X_train_cv = X_train[train_idx]\n",
    "        y_train_cv = target_train[train_idx]\n",
    "        X_holdout = X_train[test_idx]\n",
    "        Y_holdout= target_train[test_idx]\n",
    "        \n",
    "        #Angle\n",
    "        X_angle_cv=X_angle[train_idx]\n",
    "        X_angle_hold=X_angle[test_idx]\n",
    "\n",
    "        #define file path and get callbacks\n",
    "        file_path = \"%s_aug_model_weights.hdf5\"%j\n",
    "        callbacks = get_callbacks(filepath=file_path, patience=10)\n",
    "        gen_flow = gen_flow_for_two_inputs(X_train_cv, X_angle_cv, y_train_cv)\n",
    "        #gen_flow = gen_flow_for_one_input(X_train_cv, y_train_cv)\n",
    "        #galaxyModel= create_model()\n",
    "        galaxyModel= getVggAngleModel()\n",
    "        galaxyModel.fit_generator(\n",
    "                gen_flow,\n",
    "                steps_per_epoch=24,\n",
    "                epochs=100,\n",
    "                shuffle=True,\n",
    "                verbose=1,\n",
    "                validation_data=([X_holdout,X_angle_hold], Y_holdout),\n",
    "                #validation_data=(X_holdout, Y_holdout),\n",
    "                callbacks=callbacks)\n",
    "\n",
    "        #Getting the Best Model\n",
    "        galaxyModel.load_weights(filepath=file_path)\n",
    "        #Getting Training Score\n",
    "        score = galaxyModel.evaluate([X_train_cv,X_angle_cv], y_train_cv, verbose=0)\n",
    "        #score = galaxyModel.evaluate(X_train_cv, y_train_cv, verbose=0)\n",
    "        print('Train loss:', score[0])\n",
    "        print('Train accuracy:', score[1])\n",
    "        #Getting Test Score\n",
    "        score = galaxyModel.evaluate([X_holdout,X_angle_hold], Y_holdout, verbose=0)\n",
    "        #score = galaxyModel.evaluate(X_holdout, Y_holdout, verbose=0)\n",
    "        print('Test loss:', score[0])\n",
    "        print('Test accuracy:', score[1])\n",
    "\n",
    "        #Getting validation Score.\n",
    "        pred_valid=galaxyModel.predict([X_holdout,X_angle_hold])\n",
    "        y_valid_pred_log[test_idx] = pred_valid.reshape(pred_valid.shape[0])\n",
    "        #pred_valid=galaxyModel.predict(X_holdout)\n",
    "\n",
    "        #Getting Test Scores\n",
    "        temp_test=galaxyModel.predict([X_test, X_test_angle])\n",
    "        #temp_test=galaxyModel.predict(X_test)\n",
    "        y_test_pred_log+=temp_test.reshape(temp_test.shape[0])\n",
    "\n",
    "        #Getting Train Scores\n",
    "        temp_train=galaxyModel.predict([X_train, X_angle])\n",
    "        #temp_train=galaxyModel.predict(X_train)\n",
    "        y_train_pred_log+=temp_train.reshape(temp_train.shape[0])\n",
    "\n",
    "    y_test_pred_log=y_test_pred_log/K\n",
    "    y_train_pred_log=y_train_pred_log/K\n",
    "\n",
    "    print('\\n Train Log Loss Validation= ',log_loss(target_train, y_train_pred_log))\n",
    "    print(' Test Log Loss Validation= ',log_loss(target_train, y_valid_pred_log))\n",
    "    return y_test_pred_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-25T18:49:12.272846Z",
     "start_time": "2017-12-25T18:47:37.700122Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===================FOLD= 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\software\\anaconda\\lib\\site-packages\\ipykernel_launcher.py:18: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=Tensor(\"de...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "24/24 [==============================] - ETA: 3:50 - loss: 1.3118 - acc: 0.500 - ETA: 1:58 - loss: 1.0829 - acc: 0.515 - ETA: 1:21 - loss: 1.0897 - acc: 0.458 - ETA: 1:02 - loss: 1.0663 - acc: 0.453 - ETA: 50s - loss: 0.9883 - acc: 0.481 - ETA: 41s - loss: 0.9761 - acc: 0.47 - ETA: 35s - loss: 0.9539 - acc: 0.48 - ETA: 31s - loss: 0.9415 - acc: 0.48 - ETA: 27s - loss: 0.9629 - acc: 0.47 - ETA: 23s - loss: 0.9481 - acc: 0.49 - ETA: 21s - loss: 0.9328 - acc: 0.49 - ETA: 18s - loss: 0.9155 - acc: 0.50 - ETA: 16s - loss: 0.9082 - acc: 0.50 - ETA: 14s - loss: 0.8961 - acc: 0.51 - ETA: 12s - loss: 0.8896 - acc: 0.51 - ETA: 10s - loss: 0.9016 - acc: 0.51 - ETA: 9s - loss: 0.8927 - acc: 0.5221 - ETA: 7s - loss: 0.9029 - acc: 0.524 - ETA: 6s - loss: 0.9043 - acc: 0.523 - ETA: 4s - loss: 0.8969 - acc: 0.525 - ETA: 3s - loss: 0.8877 - acc: 0.532 - ETA: 2s - loss: 0.8813 - acc: 0.535 - ETA: 1s - loss: 0.8768 - acc: 0.535 - 41s 2s/step - loss: 0.8814 - acc: 0.5352 - val_loss: 0.7182 - val_acc: 0.4689\n",
      "Epoch 2/100\n",
      "24/24 [==============================] - ETA: 19s - loss: 0.8814 - acc: 0.56 - ETA: 18s - loss: 0.9882 - acc: 0.45 - ETA: 17s - loss: 0.9089 - acc: 0.50 - ETA: 16s - loss: 0.8595 - acc: 0.53 - ETA: 15s - loss: 0.9024 - acc: 0.52 - ETA: 14s - loss: 0.9230 - acc: 0.51 - ETA: 13s - loss: 0.9178 - acc: 0.51 - ETA: 12s - loss: 0.9207 - acc: 0.51 - ETA: 11s - loss: 0.9081 - acc: 0.51 - ETA: 11s - loss: 0.9065 - acc: 0.51 - ETA: 10s - loss: 0.9058 - acc: 0.51 - ETA: 9s - loss: 0.9187 - acc: 0.5052 - ETA: 8s - loss: 0.9066 - acc: 0.507 - ETA: 7s - loss: 0.9021 - acc: 0.506 - ETA: 7s - loss: 0.8983 - acc: 0.512 - ETA: 6s - loss: 0.8916 - acc: 0.509 - ETA: 5s - loss: 0.8972 - acc: 0.509 - ETA: 4s - loss: 0.8987 - acc: 0.506 - ETA: 3s - loss: 0.8983 - acc: 0.504 - ETA: 3s - loss: 0.8879 - acc: 0.509 - ETA: 2s - loss: 0.8861 - acc: 0.511 - ETA: 1s - loss: 0.8770 - acc: 0.515 - ETA: 0s - loss: 0.8764 - acc: 0.517 - 25s 1s/step - loss: 0.8724 - acc: 0.5183 - val_loss: 0.7035 - val_acc: 0.4689\n",
      "Epoch 3/100\n",
      " 7/24 [=======>......................] - ETA: 18s - loss: 1.0401 - acc: 0.37 - ETA: 17s - loss: 0.8731 - acc: 0.48 - ETA: 16s - loss: 0.8479 - acc: 0.51 - ETA: 15s - loss: 0.8477 - acc: 0.52 - ETA: 15s - loss: 0.8090 - acc: 0.54 - ETA: 14s - loss: 0.8211 - acc: 0.53 - ETA: 13s - loss: 0.8127 - acc: 0.5312"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[32,64,224,224]\n\t [[Node: training_1/Adam/gradients/block1_pool_1/MaxPool_grad/MaxPoolGrad = MaxPoolGrad[T=DT_FLOAT, _class=[\"loc:@block1_pool_1/MaxPool\"], data_format=\"NHWC\", ksize=[1, 2, 2, 1], padding=\"VALID\", strides=[1, 2, 2, 1], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](block1_conv2_1/Relu, block1_pool_1/MaxPool, training_1/Adam/gradients/block2_conv1_1/convolution_grad/Conv2DBackpropInput)]]\n\nCaused by op 'training_1/Adam/gradients/block1_pool_1/MaxPool_grad/MaxPoolGrad', defined at:\n  File \"E:\\software\\anaconda\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"E:\\software\\anaconda\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"E:\\software\\anaconda\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"E:\\software\\anaconda\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"E:\\software\\anaconda\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"E:\\software\\anaconda\\lib\\site-packages\\zmq\\eventloop\\ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"E:\\software\\anaconda\\lib\\site-packages\\tornado\\ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"E:\\software\\anaconda\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"E:\\software\\anaconda\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"E:\\software\\anaconda\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"E:\\software\\anaconda\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"E:\\software\\anaconda\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"E:\\software\\anaconda\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"E:\\software\\anaconda\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"E:\\software\\anaconda\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"E:\\software\\anaconda\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"E:\\software\\anaconda\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"E:\\software\\anaconda\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2698, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"E:\\software\\anaconda\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2802, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"E:\\software\\anaconda\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2862, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-16-f2eabcf36440>\", line 1, in <module>\n    preds=myAngleCV(X_train_re, X_angle, X_test_re)\n  File \"<ipython-input-13-df45d66aa2de>\", line 34, in myAngleCV\n    callbacks=callbacks)\n  File \"E:\\software\\anaconda\\lib\\site-packages\\keras\\legacy\\interfaces.py\", line 87, in wrapper\n    return func(*args, **kwargs)\n  File \"E:\\software\\anaconda\\lib\\site-packages\\keras\\engine\\training.py\", line 1961, in fit_generator\n    self._make_train_function()\n  File \"E:\\software\\anaconda\\lib\\site-packages\\keras\\engine\\training.py\", line 990, in _make_train_function\n    loss=self.total_loss)\n  File \"E:\\software\\anaconda\\lib\\site-packages\\keras\\legacy\\interfaces.py\", line 87, in wrapper\n    return func(*args, **kwargs)\n  File \"E:\\software\\anaconda\\lib\\site-packages\\keras\\optimizers.py\", line 415, in get_updates\n    grads = self.get_gradients(loss, params)\n  File \"E:\\software\\anaconda\\lib\\site-packages\\keras\\optimizers.py\", line 73, in get_gradients\n    grads = K.gradients(loss, params)\n  File \"E:\\software\\anaconda\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\", line 2369, in gradients\n    return tf.gradients(loss, variables, colocate_gradients_with_ops=True)\n  File \"E:\\software\\anaconda\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py\", line 581, in gradients\n    grad_scope, op, func_call, lambda: grad_fn(op, *out_grads))\n  File \"E:\\software\\anaconda\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py\", line 353, in _MaybeCompile\n    return grad_fn()  # Exit early\n  File \"E:\\software\\anaconda\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py\", line 581, in <lambda>\n    grad_scope, op, func_call, lambda: grad_fn(op, *out_grads))\n  File \"E:\\software\\anaconda\\lib\\site-packages\\tensorflow\\python\\ops\\nn_grad.py\", line 555, in _MaxPoolGrad\n    data_format=op.get_attr(\"data_format\"))\n  File \"E:\\software\\anaconda\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py\", line 3082, in _max_pool_grad\n    data_format=data_format, name=name)\n  File \"E:\\software\\anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"E:\\software\\anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2956, in create_op\n    op_def=op_def)\n  File \"E:\\software\\anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1470, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\n...which was originally created as op 'block1_pool_1/MaxPool', defined at:\n  File \"E:\\software\\anaconda\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n[elided 19 identical lines from previous traceback]\n  File \"<ipython-input-16-f2eabcf36440>\", line 1, in <module>\n    preds=myAngleCV(X_train_re, X_angle, X_test_re)\n  File \"<ipython-input-13-df45d66aa2de>\", line 25, in myAngleCV\n    galaxyModel= getVggAngleModel()\n  File \"<ipython-input-11-816f6ce0d87b>\", line 5, in getVggAngleModel\n    input_shape=X_train_re.shape[1:], classes=1)\n  File \"E:\\software\\anaconda\\lib\\site-packages\\keras\\applications\\vgg16.py\", line 114, in VGG16\n    x = MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool')(x)\n  File \"E:\\software\\anaconda\\lib\\site-packages\\keras\\engine\\topology.py\", line 603, in __call__\n    output = self.call(inputs, **kwargs)\n  File \"E:\\software\\anaconda\\lib\\site-packages\\keras\\layers\\pooling.py\", line 154, in call\n    data_format=self.data_format)\n  File \"E:\\software\\anaconda\\lib\\site-packages\\keras\\layers\\pooling.py\", line 217, in _pooling_function\n    pool_mode='max')\n  File \"E:\\software\\anaconda\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\", line 3456, in pool2d\n    data_format=tf_data_format)\n  File \"E:\\software\\anaconda\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 1958, in max_pool\n    name=name)\n  File \"E:\\software\\anaconda\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py\", line 2805, in _max_pool\n    data_format=data_format, name=name)\n  File \"E:\\software\\anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"E:\\software\\anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2956, in create_op\n    op_def=op_def)\n  File \"E:\\software\\anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1470, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[32,64,224,224]\n\t [[Node: training_1/Adam/gradients/block1_pool_1/MaxPool_grad/MaxPoolGrad = MaxPoolGrad[T=DT_FLOAT, _class=[\"loc:@block1_pool_1/MaxPool\"], data_format=\"NHWC\", ksize=[1, 2, 2, 1], padding=\"VALID\", strides=[1, 2, 2, 1], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](block1_conv2_1/Relu, block1_pool_1/MaxPool, training_1/Adam/gradients/block2_conv1_1/convolution_grad/Conv2DBackpropInput)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32mE:\\software\\anaconda\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1322\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1323\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1324\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\software\\anaconda\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1302\u001b[1;33m                                    status, run_metadata)\n\u001b[0m\u001b[0;32m   1303\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\software\\anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[0;32m    472\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 473\u001b[1;33m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[0;32m    474\u001b[0m     \u001b[1;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[32,64,224,224]\n\t [[Node: training_1/Adam/gradients/block1_pool_1/MaxPool_grad/MaxPoolGrad = MaxPoolGrad[T=DT_FLOAT, _class=[\"loc:@block1_pool_1/MaxPool\"], data_format=\"NHWC\", ksize=[1, 2, 2, 1], padding=\"VALID\", strides=[1, 2, 2, 1], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](block1_conv2_1/Relu, block1_pool_1/MaxPool, training_1/Adam/gradients/block2_conv1_1/convolution_grad/Conv2DBackpropInput)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-f2eabcf36440>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpreds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmyAngleCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_re\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_angle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test_re\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-13-df45d66aa2de>\u001b[0m in \u001b[0;36mmyAngleCV\u001b[1;34m(X_train, X_angle, X_test)\u001b[0m\n\u001b[0;32m     32\u001b[0m                 \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mX_holdout\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_angle_hold\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_holdout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m                 \u001b[1;31m#validation_data=(X_holdout, Y_holdout),\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m                 callbacks=callbacks)\n\u001b[0m\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m         \u001b[1;31m#Getting the Best Model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\software\\anaconda\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     85\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[0;32m     86\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 87\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\software\\anaconda\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   2075\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[0;32m   2076\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2077\u001b[1;33m                                                class_weight=class_weight)\n\u001b[0m\u001b[0;32m   2078\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2079\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\software\\anaconda\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[0;32m   1795\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1796\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1797\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1798\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1799\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\software\\anaconda\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2330\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[0;32m   2331\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2332\u001b[1;33m                               **self.session_kwargs)\n\u001b[0m\u001b[0;32m   2333\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2334\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\software\\anaconda\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    887\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 889\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    890\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\software\\anaconda\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1118\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1120\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1121\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\software\\anaconda\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1315\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[1;32m-> 1317\u001b[1;33m                            options, run_metadata)\n\u001b[0m\u001b[0;32m   1318\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1319\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\software\\anaconda\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1334\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1335\u001b[0m           \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1336\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1337\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1338\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[32,64,224,224]\n\t [[Node: training_1/Adam/gradients/block1_pool_1/MaxPool_grad/MaxPoolGrad = MaxPoolGrad[T=DT_FLOAT, _class=[\"loc:@block1_pool_1/MaxPool\"], data_format=\"NHWC\", ksize=[1, 2, 2, 1], padding=\"VALID\", strides=[1, 2, 2, 1], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](block1_conv2_1/Relu, block1_pool_1/MaxPool, training_1/Adam/gradients/block2_conv1_1/convolution_grad/Conv2DBackpropInput)]]\n\nCaused by op 'training_1/Adam/gradients/block1_pool_1/MaxPool_grad/MaxPoolGrad', defined at:\n  File \"E:\\software\\anaconda\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"E:\\software\\anaconda\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"E:\\software\\anaconda\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"E:\\software\\anaconda\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"E:\\software\\anaconda\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"E:\\software\\anaconda\\lib\\site-packages\\zmq\\eventloop\\ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"E:\\software\\anaconda\\lib\\site-packages\\tornado\\ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"E:\\software\\anaconda\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"E:\\software\\anaconda\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"E:\\software\\anaconda\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"E:\\software\\anaconda\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"E:\\software\\anaconda\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"E:\\software\\anaconda\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"E:\\software\\anaconda\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"E:\\software\\anaconda\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"E:\\software\\anaconda\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"E:\\software\\anaconda\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"E:\\software\\anaconda\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2698, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"E:\\software\\anaconda\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2802, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"E:\\software\\anaconda\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2862, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-16-f2eabcf36440>\", line 1, in <module>\n    preds=myAngleCV(X_train_re, X_angle, X_test_re)\n  File \"<ipython-input-13-df45d66aa2de>\", line 34, in myAngleCV\n    callbacks=callbacks)\n  File \"E:\\software\\anaconda\\lib\\site-packages\\keras\\legacy\\interfaces.py\", line 87, in wrapper\n    return func(*args, **kwargs)\n  File \"E:\\software\\anaconda\\lib\\site-packages\\keras\\engine\\training.py\", line 1961, in fit_generator\n    self._make_train_function()\n  File \"E:\\software\\anaconda\\lib\\site-packages\\keras\\engine\\training.py\", line 990, in _make_train_function\n    loss=self.total_loss)\n  File \"E:\\software\\anaconda\\lib\\site-packages\\keras\\legacy\\interfaces.py\", line 87, in wrapper\n    return func(*args, **kwargs)\n  File \"E:\\software\\anaconda\\lib\\site-packages\\keras\\optimizers.py\", line 415, in get_updates\n    grads = self.get_gradients(loss, params)\n  File \"E:\\software\\anaconda\\lib\\site-packages\\keras\\optimizers.py\", line 73, in get_gradients\n    grads = K.gradients(loss, params)\n  File \"E:\\software\\anaconda\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\", line 2369, in gradients\n    return tf.gradients(loss, variables, colocate_gradients_with_ops=True)\n  File \"E:\\software\\anaconda\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py\", line 581, in gradients\n    grad_scope, op, func_call, lambda: grad_fn(op, *out_grads))\n  File \"E:\\software\\anaconda\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py\", line 353, in _MaybeCompile\n    return grad_fn()  # Exit early\n  File \"E:\\software\\anaconda\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py\", line 581, in <lambda>\n    grad_scope, op, func_call, lambda: grad_fn(op, *out_grads))\n  File \"E:\\software\\anaconda\\lib\\site-packages\\tensorflow\\python\\ops\\nn_grad.py\", line 555, in _MaxPoolGrad\n    data_format=op.get_attr(\"data_format\"))\n  File \"E:\\software\\anaconda\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py\", line 3082, in _max_pool_grad\n    data_format=data_format, name=name)\n  File \"E:\\software\\anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"E:\\software\\anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2956, in create_op\n    op_def=op_def)\n  File \"E:\\software\\anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1470, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\n...which was originally created as op 'block1_pool_1/MaxPool', defined at:\n  File \"E:\\software\\anaconda\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n[elided 19 identical lines from previous traceback]\n  File \"<ipython-input-16-f2eabcf36440>\", line 1, in <module>\n    preds=myAngleCV(X_train_re, X_angle, X_test_re)\n  File \"<ipython-input-13-df45d66aa2de>\", line 25, in myAngleCV\n    galaxyModel= getVggAngleModel()\n  File \"<ipython-input-11-816f6ce0d87b>\", line 5, in getVggAngleModel\n    input_shape=X_train_re.shape[1:], classes=1)\n  File \"E:\\software\\anaconda\\lib\\site-packages\\keras\\applications\\vgg16.py\", line 114, in VGG16\n    x = MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool')(x)\n  File \"E:\\software\\anaconda\\lib\\site-packages\\keras\\engine\\topology.py\", line 603, in __call__\n    output = self.call(inputs, **kwargs)\n  File \"E:\\software\\anaconda\\lib\\site-packages\\keras\\layers\\pooling.py\", line 154, in call\n    data_format=self.data_format)\n  File \"E:\\software\\anaconda\\lib\\site-packages\\keras\\layers\\pooling.py\", line 217, in _pooling_function\n    pool_mode='max')\n  File \"E:\\software\\anaconda\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\", line 3456, in pool2d\n    data_format=tf_data_format)\n  File \"E:\\software\\anaconda\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 1958, in max_pool\n    name=name)\n  File \"E:\\software\\anaconda\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py\", line 2805, in _max_pool\n    data_format=data_format, name=name)\n  File \"E:\\software\\anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"E:\\software\\anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2956, in create_op\n    op_def=op_def)\n  File \"E:\\software\\anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1470, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[32,64,224,224]\n\t [[Node: training_1/Adam/gradients/block1_pool_1/MaxPool_grad/MaxPoolGrad = MaxPoolGrad[T=DT_FLOAT, _class=[\"loc:@block1_pool_1/MaxPool\"], data_format=\"NHWC\", ksize=[1, 2, 2, 1], padding=\"VALID\", strides=[1, 2, 2, 1], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](block1_conv2_1/Relu, block1_pool_1/MaxPool, training_1/Adam/gradients/block2_conv1_1/convolution_grad/Conv2DBackpropInput)]]\n"
     ]
    }
   ],
   "source": [
    "preds=myAngleCV(X_train_re, X_angle, X_test_re)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
