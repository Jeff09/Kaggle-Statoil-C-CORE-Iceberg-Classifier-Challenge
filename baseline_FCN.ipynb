{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-25T17:32:19.554339Z",
     "start_time": "2017-12-25T17:31:44.543657Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Random initialization\n",
    "import numpy as np\n",
    "np.random.seed(98643)\n",
    "import tensorflow as tf\n",
    "tf.set_random_seed(683)\n",
    "# Uncomment this to hide TF warnings about allocation\n",
    "#import os\n",
    "#os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "# An image clearing dependencies\n",
    "from skimage.restoration import (denoise_tv_chambolle, denoise_bilateral,\n",
    "                                 denoise_wavelet, estimate_sigma, denoise_tv_bregman, denoise_nl_means)\n",
    "from skimage.filters import gaussian\n",
    "from skimage.color import rgb2gray\n",
    "\n",
    "# Data reading and visualization\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Training part\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Input, Flatten, GlobalAveragePooling2D, Lambda\n",
    "from keras.layers import GlobalMaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint, Callback, EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-25T17:32:19.582288Z",
     "start_time": "2017-12-25T17:32:19.555711Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Translate data to an image format\n",
    "def color_composite(data):\n",
    "    rgb_arrays = []\n",
    "    for i, row in data.iterrows():\n",
    "        band_1 = np.array(row['band_1']).reshape(75, 75)\n",
    "        band_2 = np.array(row['band_2']).reshape(75, 75)\n",
    "        band_3 = band_1 / band_2\n",
    "\n",
    "        r = (band_1 + abs(band_1.min())) / np.max((band_1 + abs(band_1.min())))\n",
    "        g = (band_2 + abs(band_2.min())) / np.max((band_2 + abs(band_2.min())))\n",
    "        b = (band_3 + abs(band_3.min())) / np.max((band_3 + abs(band_3.min())))\n",
    "\n",
    "        rgb = np.dstack((r, g, b))\n",
    "        rgb_arrays.append(rgb)\n",
    "    return np.array(rgb_arrays)\n",
    "\n",
    "def denoise(X, weight, multichannel):\n",
    "    return np.asarray([denoise_tv_chambolle(item, weight=weight, multichannel=multichannel) for item in X])\n",
    "\n",
    "def smooth(X, sigma):\n",
    "    return np.asarray([gaussian(item, sigma=sigma) for item in X])\n",
    "\n",
    "def grayscale(X):\n",
    "    return np.asarray([rgb2gray(item) for item in X])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-25T17:32:41.230284Z",
     "start_time": "2017-12-25T17:32:19.583801Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Load the data.\n",
    "train = pd.read_json(\"data/processed/train.json\")\n",
    "test = pd.read_json(\"data/processed/test.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-23T23:19:47.207682Z",
     "start_time": "2017-12-23T23:19:47.193647Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train.inc_angle = train.inc_angle.replace('na', 0)\n",
    "train.inc_angle = train.inc_angle.astype(float).fillna(0.0)\n",
    "train_all = True\n",
    "\n",
    "# These are train flags that required to train model more efficiently and \n",
    "# select proper model parameters\n",
    "train_b = True or train_all\n",
    "train_img = True or train_all\n",
    "train_total = True or train_all\n",
    "predict_submission = True and train_all\n",
    "\n",
    "clean_all = False\n",
    "clean_b = False or clean_all\n",
    "clean_img = False or clean_all\n",
    "\n",
    "load_all = False\n",
    "load_b = False or load_all\n",
    "load_img = False or load_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-23T23:19:48.201924Z",
     "start_time": "2017-12-23T23:19:48.145202Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_dataset(frame, labeled, smooth_rgb=0.2, smooth_gray=0.5,\n",
    "                   weight_rgb=0.05, weight_gray=0.05):\n",
    "    band_1, band_2, images = frame['band_1'].values, frame['band_2'].values, color_composite(frame)\n",
    "    to_arr = lambda x: np.asarray([np.asarray(item) for item in x])\n",
    "    band_1 = to_arr(band_1)\n",
    "    band_2 = to_arr(band_2)\n",
    "    band_3 = (band_1 + band_2) / 2\n",
    "    gray_reshape = lambda x: np.asarray([item.reshape(75, 75) for item in x])\n",
    "    # Make a picture format from flat vector\n",
    "    band_1 = gray_reshape(band_1)\n",
    "    band_2 = gray_reshape(band_2)\n",
    "    band_3 = gray_reshape(band_3)\n",
    "    print('Denoising and reshaping')\n",
    "    if train_b and clean_b:\n",
    "        # Smooth and denoise data\n",
    "        band_1 = smooth(denoise(band_1, weight_gray, False), smooth_gray)\n",
    "        print('Gray 1 done')\n",
    "        band_2 = smooth(denoise(band_2, weight_gray, False), smooth_gray)\n",
    "        print('Gray 2 done')\n",
    "        band_3 = smooth(denoise(band_3, weight_gray, False), smooth_gray)\n",
    "        print('Gray 3 done')\n",
    "    if train_img and clean_img:\n",
    "        images = smooth(denoise(images, weight_rgb, True), smooth_rgb)\n",
    "    print('RGB done')\n",
    "    tf_reshape = lambda x: np.asarray([item.reshape(75, 75, 1) for item in x])\n",
    "    band_1 = tf_reshape(band_1)\n",
    "    band_2 = tf_reshape(band_2)\n",
    "    band_3 = tf_reshape(band_3)\n",
    "    #images = tf_reshape(images)\n",
    "    band = np.concatenate([band_1, band_2, band_3], axis=3)\n",
    "    if labeled:\n",
    "        y = np.array(frame[\"is_iceberg\"])\n",
    "    else:\n",
    "        y = None\n",
    "    return y, band, images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-23T23:19:50.444669Z",
     "start_time": "2017-12-23T23:19:48.769737Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Denoising and reshaping\n",
      "RGB done\n"
     ]
    }
   ],
   "source": [
    "y_train, X_b, X_images = create_dataset(train, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-23T23:18:11.743379Z",
     "start_time": "2017-12-23T23:18:11.460764Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.ndimage import rotate as rot\n",
    "\n",
    "def augment(images):\n",
    "    image_mirror_lr = []\n",
    "    image_mirror_ud = []\n",
    "    image_rotate = []\n",
    "    for i in range(0,images.shape[0]):\n",
    "        band_1 = images[i,:,:,0]\n",
    "        band_2 = images[i,:,:,1]\n",
    "        band_3 = images[i,:,:,2]\n",
    "            \n",
    "        # mirror left-right\n",
    "        band_1_mirror_lr = np.flip(band_1, 0)\n",
    "        band_2_mirror_lr = np.flip(band_2, 0)\n",
    "        band_3_mirror_lr = np.flip(band_3, 0)\n",
    "        image_mirror_lr.append(np.dstack((band_1_mirror_lr, band_2_mirror_lr, band_3_mirror_lr)))\n",
    "        \n",
    "        # mirror up-down\n",
    "        band_1_mirror_ud = np.flip(band_1, 1)\n",
    "        band_2_mirror_ud = np.flip(band_2, 1)\n",
    "        band_3_mirror_ud = np.flip(band_3, 1)\n",
    "        image_mirror_ud.append(np.dstack((band_1_mirror_ud, band_2_mirror_ud, band_3_mirror_ud)))\n",
    "        \n",
    "        #rotate \n",
    "        band_1_rotate = rot(band_1, 30, reshape=False)\n",
    "        band_2_rotate = rot(band_2, 30, reshape=False)\n",
    "        band_3_rotate = rot(band_3, 30, reshape=False)\n",
    "        image_rotate.append(np.dstack((band_1_rotate, band_2_rotate, band_3_rotate)))\n",
    "        \n",
    "    mirrorlr = np.array(image_mirror_lr)\n",
    "    mirrorud = np.array(image_mirror_ud)\n",
    "    rotated = np.array(image_rotate)\n",
    "    images = np.concatenate((images, mirrorlr, mirrorud, rotated))\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-23T23:20:00.721713Z",
     "start_time": "2017-12-23T23:19:56.466270Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6416, 75, 75, 3)\n",
      "(6416,)\n"
     ]
    }
   ],
   "source": [
    "X_images = augment(X_images)\n",
    "y_train = np.concatenate((y_train,y_train, y_train, y_train))\n",
    "\n",
    "print (X_images.shape)\n",
    "print (y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-23T23:20:02.514086Z",
     "start_time": "2017-12-23T23:20:02.105608Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\software\\anaconda\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "X_train_cv, X_valid, y_train_cv, y_valid = train_test_split(X_images, y_train, random_state=1, train_size=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-25T17:34:48.634430Z",
     "start_time": "2017-12-25T17:34:48.606333Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "batch_size=64\n",
    "# Define the image transformations here\n",
    "gen = ImageDataGenerator(horizontal_flip = True,\n",
    "                         vertical_flip = True,\n",
    "                         width_shift_range = 0.,\n",
    "                         height_shift_range = 0.,\n",
    "                         channel_shift_range=0,\n",
    "                         zoom_range = 0.5,\n",
    "                         rotation_range = 10)\n",
    "\n",
    "# Here is the function that merges our two generators\n",
    "# We use the exact same generator with the same random seed for both the y and angle arrays\n",
    "def gen_flow_for_two_inputs(X1, X2, y):\n",
    "    genX1 = gen.flow(X1,y,  batch_size=batch_size,seed=55)\n",
    "    genX2 = gen.flow(X1,X2, batch_size=batch_size,seed=55)\n",
    "    while True:\n",
    "            X1i = genX1.next()\n",
    "            X2i = genX2.next()\n",
    "            #Assert arrays are equal - this was for peace of mind, but slows down training\n",
    "            #np.testing.assert_array_equal(X1i[0],X2i[0])\n",
    "            yield [X1i[0], X2i[1]], X1i[1]\n",
    "\n",
    "# Finally create generator\n",
    "#gen_train_flow = gen_flow(X_train_cv, y_train_cv)\n",
    "#gen_valid_flow = gen_flow(X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-25T17:35:07.299163Z",
     "start_time": "2017-12-25T17:35:07.285126Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Import Keras.\n",
    "from matplotlib import pyplot\n",
    "import keras as k\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Lambda, Activation\n",
    "from keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D, GlobalAveragePooling2D, Dense, Dropout, Input, Flatten, Activation\n",
    "from keras.layers import GlobalMaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras.models import Model\n",
    "from keras import initializers\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint, Callback, EarlyStopping, ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-23T23:18:17.359394Z",
     "start_time": "2017-12-23T23:18:17.145324Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#define our model\n",
    "def getModel():\n",
    "    #Building the model\n",
    "    gmodel=Sequential()\n",
    "    #Conv Layer 1\n",
    "    gmodel.add(Conv2D(64, kernel_size=(3, 3),activation='relu', input_shape=(75, 75, 3)))\n",
    "    gmodel.add(BatchNormalization())\n",
    "    gmodel.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))\n",
    "    gmodel.add(Dropout(0.2))\n",
    "\n",
    "    #Conv Layer 2\n",
    "    gmodel.add(Conv2D(128, kernel_size=(3, 3), activation='relu' ))\n",
    "    gmodel.add(BatchNormalization())\n",
    "    gmodel.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "    gmodel.add(Dropout(0.2))\n",
    "\n",
    "    #Conv Layer 3\n",
    "    gmodel.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "    gmodel.add(BatchNormalization())\n",
    "    gmodel.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "    gmodel.add(Dropout(0.2))\n",
    "\n",
    "    #Conv Layer 4\n",
    "    gmodel.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "    gmodel.add(BatchNormalization())\n",
    "    gmodel.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "    gmodel.add(Dropout(0.2))\n",
    "\n",
    "    #Flatten the data for upcoming dense layers\n",
    "    gmodel.add(Flatten())\n",
    "\n",
    "    #Dense Layers\n",
    "    gmodel.add(Dense(512))\n",
    "    gmodel.add(Activation('relu'))\n",
    "    gmodel.add(BatchNormalization())\n",
    "    gmodel.add(Dropout(0.2))\n",
    "\n",
    "    #Dense Layer 2\n",
    "    gmodel.add(Dense(256))\n",
    "    gmodel.add(Activation('relu'))\n",
    "    gmodel.add(BatchNormalization())\n",
    "    gmodel.add(Dropout(0.2))\n",
    "\n",
    "    #Sigmoid Layer\n",
    "    gmodel.add(Dense(1))\n",
    "    gmodel.add(Activation('sigmoid'))\n",
    "\n",
    "    mypotim=Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "    gmodel.compile(loss='binary_crossentropy',\n",
    "                  optimizer=mypotim,\n",
    "                  metrics=['accuracy'])\n",
    "    gmodel.summary()\n",
    "    return gmodel\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-25T17:35:32.033731Z",
     "start_time": "2017-12-25T17:35:31.973521Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ConvBlock(model, layers, filters):\n",
    "    '''Create [layers] layers consisting of zero padding, a convolution with [filters] 3x3 filters and batch normalization. Perform max pooling after the last layer.'''\n",
    "    for i in range(layers):\n",
    "        model.add(ZeroPadding2D((1, 1)))\n",
    "        model.add(Conv2D(filters, (3, 3), activation='relu'))\n",
    "        model.add(BatchNormalization(axis=3))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "def create_model():\n",
    "    '''Create the FCN and return a keras model.'''\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    # Input image: 75x75x3\n",
    "    model.add(Lambda(lambda x: x, input_shape=(75, 75, 3)))\n",
    "    ConvBlock(model, 1, 32)\n",
    "    # 37x37x32\n",
    "    ConvBlock(model, 1, 64)\n",
    "    # 18x18x64\n",
    "    ConvBlock(model, 1, 128)\n",
    "    # 9x9x128\n",
    "    ConvBlock(model, 1, 128)\n",
    "    # 4x4x128\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Conv2D(2, (3, 3), activation='relu'))\n",
    "    model.add(GlobalAveragePooling2D())\n",
    "    # 4x4x2\n",
    "    #model.add(Activation('softmax'))\n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation('sigmoid'))\n",
    "    \n",
    "    mypotim=Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer=mypotim,\n",
    "                  metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-25T17:38:18.542547Z",
     "start_time": "2017-12-25T17:38:18.533023Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_callbacks(filepath, patience=2):\n",
    "    es = EarlyStopping('val_loss', patience=patience, mode=\"min\")\n",
    "    reduce_lr_loss = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=7, verbose=1, epsilon=1e-4, mode='min')\n",
    "    msave = ModelCheckpoint(filepath, save_best_only=True)\n",
    "    return [msave,reduce_lr_loss, es]\n",
    "file_path = \".model_weights.hdf5\"\n",
    "callbacks = get_callbacks(filepath=file_path, patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-25T17:38:25.851329Z",
     "start_time": "2017-12-25T17:38:25.581160Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-22T20:38:35.479033Z",
     "start_time": "2017-12-22T20:31:22.274180Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_5 (Conv2D)            (None, 73, 73, 64)        1792      \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 73, 73, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 36, 36, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 36, 36, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 34, 34, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 34, 34, 128)       512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 17, 17, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 17, 17, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 15, 15, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 15, 15, 128)       512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 5, 5, 64)          73792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 5, 5, 64)          256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 2, 2, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 2, 2, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 257       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 564,801\n",
      "Trainable params: 562,497\n",
      "Non-trainable params: 2,304\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "201/200 [==============================] - 10s 51ms/step - loss: 0.5499 - acc: 0.7372 - val_loss: 1.4525 - val_acc: 0.5312\n",
      "Epoch 2/50\n",
      "201/200 [==============================] - 8s 42ms/step - loss: 0.4212 - acc: 0.8001 - val_loss: 2.3606 - val_acc: 0.5305\n",
      "Epoch 3/50\n",
      "201/200 [==============================] - 8s 41ms/step - loss: 0.3924 - acc: 0.8159 - val_loss: 1.4000 - val_acc: 0.5356\n",
      "Epoch 4/50\n",
      "201/200 [==============================] - 8s 42ms/step - loss: 0.3826 - acc: 0.8215 - val_loss: 0.4367 - val_acc: 0.8092\n",
      "Epoch 5/50\n",
      "201/200 [==============================] - 8s 42ms/step - loss: 0.3639 - acc: 0.8252 - val_loss: 0.5095 - val_acc: 0.7405\n",
      "Epoch 6/50\n",
      "201/200 [==============================] - 8s 42ms/step - loss: 0.3630 - acc: 0.8260 - val_loss: 0.4293 - val_acc: 0.8111\n",
      "Epoch 7/50\n",
      "201/200 [==============================] - 8s 42ms/step - loss: 0.3418 - acc: 0.8411 - val_loss: 0.4064 - val_acc: 0.8047\n",
      "Epoch 8/50\n",
      "201/200 [==============================] - 8s 42ms/step - loss: 0.3339 - acc: 0.8461 - val_loss: 0.3835 - val_acc: 0.8041\n",
      "Epoch 9/50\n",
      "201/200 [==============================] - 8s 42ms/step - loss: 0.3271 - acc: 0.8511 - val_loss: 0.5154 - val_acc: 0.7303\n",
      "Epoch 10/50\n",
      "201/200 [==============================] - 9s 45ms/step - loss: 0.3359 - acc: 0.8444 - val_loss: 0.3064 - val_acc: 0.8702\n",
      "Epoch 11/50\n",
      "201/200 [==============================] - 8s 42ms/step - loss: 0.3148 - acc: 0.8543 - val_loss: 0.4414 - val_acc: 0.8142\n",
      "Epoch 12/50\n",
      "201/200 [==============================] - 8s 42ms/step - loss: 0.3109 - acc: 0.8570 - val_loss: 0.3724 - val_acc: 0.8282\n",
      "Epoch 13/50\n",
      "201/200 [==============================] - 8s 42ms/step - loss: 0.3117 - acc: 0.8599 - val_loss: 0.5261 - val_acc: 0.7373\n",
      "Epoch 14/50\n",
      "201/200 [==============================] - 9s 46ms/step - loss: 0.3016 - acc: 0.8679 - val_loss: 0.2831 - val_acc: 0.8823\n",
      "Epoch 15/50\n",
      "201/200 [==============================] - 8s 42ms/step - loss: 0.3210 - acc: 0.8592 - val_loss: 0.3530 - val_acc: 0.8257\n",
      "Epoch 16/50\n",
      "201/200 [==============================] - 8s 42ms/step - loss: 0.3038 - acc: 0.8642 - val_loss: 0.6202 - val_acc: 0.7265\n",
      "Epoch 17/50\n",
      "201/200 [==============================] - 8s 42ms/step - loss: 0.2916 - acc: 0.8700 - val_loss: 0.7902 - val_acc: 0.7029\n",
      "Epoch 18/50\n",
      "201/200 [==============================] - 9s 45ms/step - loss: 0.2972 - acc: 0.8727 - val_loss: 0.2502 - val_acc: 0.8969\n",
      "Epoch 19/50\n",
      "201/200 [==============================] - 8s 41ms/step - loss: 0.2941 - acc: 0.8761 - val_loss: 0.2848 - val_acc: 0.8721\n",
      "Epoch 20/50\n",
      "201/200 [==============================] - 8s 42ms/step - loss: 0.2944 - acc: 0.8743 - val_loss: 0.3947 - val_acc: 0.8314\n",
      "Epoch 21/50\n",
      "201/200 [==============================] - 8s 42ms/step - loss: 0.2929 - acc: 0.8751 - val_loss: 0.3831 - val_acc: 0.8314\n",
      "Epoch 22/50\n",
      "201/200 [==============================] - 8s 42ms/step - loss: 0.2930 - acc: 0.8721 - val_loss: 0.5752 - val_acc: 0.7634\n",
      "Epoch 23/50\n",
      "201/200 [==============================] - 8s 41ms/step - loss: 0.2853 - acc: 0.8757 - val_loss: 0.3290 - val_acc: 0.8473\n",
      "Epoch 24/50\n",
      "200/200 [============================>.] - ETA: 0s - loss: 0.2800 - acc: 0.8827\n",
      "Epoch 00024: reducing learning rate to 0.00010000000474974513.\n",
      "201/200 [==============================] - 8s 42ms/step - loss: 0.2799 - acc: 0.8825 - val_loss: 0.3062 - val_acc: 0.8658\n",
      "Epoch 25/50\n",
      "201/200 [==============================] - 9s 46ms/step - loss: 0.2667 - acc: 0.8904 - val_loss: 0.2417 - val_acc: 0.8963\n",
      "Epoch 26/50\n",
      "201/200 [==============================] - 9s 47ms/step - loss: 0.2551 - acc: 0.8943 - val_loss: 0.2244 - val_acc: 0.9167\n",
      "Epoch 27/50\n",
      "201/200 [==============================] - 9s 46ms/step - loss: 0.2457 - acc: 0.8952 - val_loss: 0.2157 - val_acc: 0.9167\n",
      "Epoch 28/50\n",
      "201/200 [==============================] - 8s 42ms/step - loss: 0.2407 - acc: 0.8995 - val_loss: 0.2274 - val_acc: 0.9109\n",
      "Epoch 29/50\n",
      "201/200 [==============================] - 8s 42ms/step - loss: 0.2447 - acc: 0.8964 - val_loss: 0.2350 - val_acc: 0.9065\n",
      "Epoch 30/50\n",
      "201/200 [==============================] - 8s 42ms/step - loss: 0.2382 - acc: 0.8996 - val_loss: 0.2260 - val_acc: 0.9192\n",
      "Epoch 31/50\n",
      "201/200 [==============================] - 8s 42ms/step - loss: 0.2537 - acc: 0.8932 - val_loss: 0.2167 - val_acc: 0.9186\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/50\n",
      "201/200 [==============================] - 9s 44ms/step - loss: 0.2306 - acc: 0.9070 - val_loss: 0.2136 - val_acc: 0.9141\n",
      "Epoch 33/50\n",
      "201/200 [==============================] - 8s 41ms/step - loss: 0.2429 - acc: 0.8991 - val_loss: 0.2308 - val_acc: 0.9116\n",
      "Epoch 34/50\n",
      "201/200 [==============================] - 8s 41ms/step - loss: 0.2339 - acc: 0.9012 - val_loss: 0.2206 - val_acc: 0.9052\n",
      "Epoch 35/50\n",
      "201/200 [==============================] - 9s 45ms/step - loss: 0.2455 - acc: 0.8987 - val_loss: 0.2087 - val_acc: 0.9186\n",
      "Epoch 36/50\n",
      "201/200 [==============================] - 8s 41ms/step - loss: 0.2351 - acc: 0.9041 - val_loss: 0.2280 - val_acc: 0.9059\n",
      "Epoch 37/50\n",
      "201/200 [==============================] - 8s 41ms/step - loss: 0.2371 - acc: 0.9054 - val_loss: 0.2143 - val_acc: 0.9167\n",
      "Epoch 38/50\n",
      "201/200 [==============================] - 9s 46ms/step - loss: 0.2361 - acc: 0.9024 - val_loss: 0.2026 - val_acc: 0.9249\n",
      "Epoch 39/50\n",
      "201/200 [==============================] - 9s 45ms/step - loss: 0.2309 - acc: 0.9058 - val_loss: 0.2024 - val_acc: 0.9224\n",
      "Epoch 40/50\n",
      "201/200 [==============================] - 8s 41ms/step - loss: 0.2318 - acc: 0.9065 - val_loss: 0.2222 - val_acc: 0.9109\n",
      "Epoch 41/50\n",
      "201/200 [==============================] - 8s 41ms/step - loss: 0.2306 - acc: 0.9052 - val_loss: 0.2202 - val_acc: 0.9071\n",
      "Epoch 42/50\n",
      "201/200 [==============================] - 8s 42ms/step - loss: 0.2319 - acc: 0.9054 - val_loss: 0.2060 - val_acc: 0.9218\n",
      "Epoch 43/50\n",
      "201/200 [==============================] - 8s 41ms/step - loss: 0.2347 - acc: 0.9040 - val_loss: 0.2124 - val_acc: 0.9141\n",
      "Epoch 44/50\n",
      "201/200 [==============================] - 8s 42ms/step - loss: 0.2317 - acc: 0.9026 - val_loss: 0.2057 - val_acc: 0.9179\n",
      "Epoch 45/50\n",
      "201/200 [==============================] - 9s 45ms/step - loss: 0.2256 - acc: 0.9044 - val_loss: 0.1993 - val_acc: 0.9268\n",
      "Epoch 46/50\n",
      "201/200 [==============================] - 8s 42ms/step - loss: 0.2260 - acc: 0.9085 - val_loss: 0.2063 - val_acc: 0.9211\n",
      "Epoch 47/50\n",
      "201/200 [==============================] - 9s 46ms/step - loss: 0.2295 - acc: 0.9028 - val_loss: 0.1991 - val_acc: 0.9218\n",
      "Epoch 48/50\n",
      "201/200 [==============================] - 9s 46ms/step - loss: 0.2224 - acc: 0.9093 - val_loss: 0.1944 - val_acc: 0.9243\n",
      "Epoch 49/50\n",
      "201/200 [==============================] - 8s 41ms/step - loss: 0.2203 - acc: 0.9115 - val_loss: 0.2289 - val_acc: 0.9090\n",
      "Epoch 50/50\n",
      "201/200 [==============================] - 8s 41ms/step - loss: 0.2275 - acc: 0.9028 - val_loss: 0.2007 - val_acc: 0.9211\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "gmodel=getModel()\n",
    "\n",
    "history = gmodel.fit_generator(gen_train_flow, \n",
    "                               validation_data=gen_valid_flow, \n",
    "                               steps_per_epoch=len(X_images) / batch_size, \n",
    "                               epochs=50,validation_steps=50, \n",
    "                               #callbacks=[ModelCheckpoint(file_path, save_best_only=True)])\n",
    "                               callbacks = callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-22T20:54:33.696883Z",
     "start_time": "2017-12-22T20:47:53.500296Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lambda_6 (Lambda)            (None, 75, 75, 3)         0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_21 (ZeroPaddi (None, 77, 77, 3)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_29 (Conv2D)           (None, 75, 75, 32)        896       \n",
      "_________________________________________________________________\n",
      "batch_normalization_29 (Batc (None, 75, 75, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_25 (MaxPooling (None, 37, 37, 32)        0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_22 (ZeroPaddi (None, 39, 39, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_30 (Conv2D)           (None, 37, 37, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_30 (Batc (None, 37, 37, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_26 (MaxPooling (None, 18, 18, 64)        0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_23 (ZeroPaddi (None, 20, 20, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_31 (Conv2D)           (None, 18, 18, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_31 (Batc (None, 18, 18, 128)       512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_27 (MaxPooling (None, 9, 9, 128)         0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_24 (ZeroPaddi (None, 11, 11, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_32 (Conv2D)           (None, 9, 9, 128)         147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_32 (Batc (None, 9, 9, 128)         512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_28 (MaxPooling (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_25 (ZeroPaddi (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_33 (Conv2D)           (None, 4, 4, 2)           2306      \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_5 ( (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 3         \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 244,549\n",
      "Trainable params: 243,845\n",
      "Non-trainable params: 704\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "201/200 [==============================] - 12s 62ms/step - loss: 0.4541 - acc: 0.7708 - val_loss: 2.1568 - val_acc: 0.5324\n",
      "Epoch 2/50\n",
      "201/200 [==============================] - 8s 41ms/step - loss: 0.3702 - acc: 0.8207 - val_loss: 0.8976 - val_acc: 0.5369\n",
      "Epoch 3/50\n",
      "201/200 [==============================] - 8s 38ms/step - loss: 0.3441 - acc: 0.8382 - val_loss: 0.9606 - val_acc: 0.6559\n",
      "Epoch 4/50\n",
      "201/200 [==============================] - 8s 40ms/step - loss: 0.3233 - acc: 0.8492 - val_loss: 0.3463 - val_acc: 0.8575\n",
      "Epoch 5/50\n",
      "201/200 [==============================] - 8s 38ms/step - loss: 0.3222 - acc: 0.8465 - val_loss: 0.4414 - val_acc: 0.7933\n",
      "Epoch 6/50\n",
      "201/200 [==============================] - 8s 38ms/step - loss: 0.3022 - acc: 0.8587 - val_loss: 1.6568 - val_acc: 0.6183\n",
      "Epoch 7/50\n",
      "201/200 [==============================] - 8s 38ms/step - loss: 0.2991 - acc: 0.8610 - val_loss: 0.5351 - val_acc: 0.7723\n",
      "Epoch 8/50\n",
      "201/200 [==============================] - 8s 39ms/step - loss: 0.2873 - acc: 0.8666 - val_loss: 0.6192 - val_acc: 0.6686\n",
      "Epoch 9/50\n",
      "201/200 [==============================] - 8s 39ms/step - loss: 0.2880 - acc: 0.8633 - val_loss: 0.4245 - val_acc: 0.8003\n",
      "Epoch 10/50\n",
      "201/200 [==============================] - 8s 38ms/step - loss: 0.2801 - acc: 0.8707 - val_loss: 0.3513 - val_acc: 0.8244\n",
      "Epoch 11/50\n",
      "201/200 [==============================] - 8s 39ms/step - loss: 0.2833 - acc: 0.8705 - val_loss: 0.4620 - val_acc: 0.7831\n",
      "Epoch 12/50\n",
      "201/200 [==============================] - 9s 43ms/step - loss: 0.2753 - acc: 0.8747 - val_loss: 0.2927 - val_acc: 0.8645\n",
      "Epoch 13/50\n",
      "201/200 [==============================] - 9s 42ms/step - loss: 0.2624 - acc: 0.8800 - val_loss: 0.2744 - val_acc: 0.8702\n",
      "Epoch 14/50\n",
      "201/200 [==============================] - 9s 42ms/step - loss: 0.2573 - acc: 0.8853 - val_loss: 0.2637 - val_acc: 0.8861\n",
      "Epoch 15/50\n",
      "201/200 [==============================] - 8s 40ms/step - loss: 0.2485 - acc: 0.8921 - val_loss: 0.2892 - val_acc: 0.8511\n",
      "Epoch 16/50\n",
      "201/200 [==============================] - 8s 39ms/step - loss: 0.2548 - acc: 0.8876 - val_loss: 0.7422 - val_acc: 0.7824\n",
      "Epoch 17/50\n",
      "201/200 [==============================] - 8s 39ms/step - loss: 0.2498 - acc: 0.8911 - val_loss: 0.2975 - val_acc: 0.8721\n",
      "Epoch 18/50\n",
      "201/200 [==============================] - 8s 41ms/step - loss: 0.2359 - acc: 0.9039 - val_loss: 0.2425 - val_acc: 0.8950\n",
      "Epoch 19/50\n",
      "201/200 [==============================] - 8s 39ms/step - loss: 0.2367 - acc: 0.9030 - val_loss: 0.4280 - val_acc: 0.8174\n",
      "Epoch 20/50\n",
      "201/200 [==============================] - 8s 39ms/step - loss: 0.2312 - acc: 0.9025 - val_loss: 0.3660 - val_acc: 0.8352\n",
      "Epoch 21/50\n",
      "201/200 [==============================] - 8s 38ms/step - loss: 0.2303 - acc: 0.9013 - val_loss: 0.2984 - val_acc: 0.8715\n",
      "Epoch 22/50\n",
      "201/200 [==============================] - 8s 38ms/step - loss: 0.2208 - acc: 0.9078 - val_loss: 0.2503 - val_acc: 0.8906\n",
      "Epoch 23/50\n",
      "201/200 [==============================] - 8s 38ms/step - loss: 0.2310 - acc: 0.9028 - val_loss: 0.4587 - val_acc: 0.7831\n",
      "Epoch 24/50\n",
      "201/200 [==============================] - 8s 41ms/step - loss: 0.2185 - acc: 0.9080 - val_loss: 0.4244 - val_acc: 0.8314\n",
      "Epoch 25/50\n",
      "201/200 [==============================] - 8s 39ms/step - loss: 0.2180 - acc: 0.9086 - val_loss: 0.2839 - val_acc: 0.8721\n",
      "Epoch 26/50\n",
      "201/200 [==============================] - 8s 39ms/step - loss: 0.2113 - acc: 0.9136 - val_loss: 0.2136 - val_acc: 0.9128\n",
      "Epoch 27/50\n",
      "201/200 [==============================] - 8s 38ms/step - loss: 0.2134 - acc: 0.9097 - val_loss: 0.2518 - val_acc: 0.8887\n",
      "Epoch 28/50\n",
      "201/200 [==============================] - 8s 39ms/step - loss: 0.2064 - acc: 0.9136 - val_loss: 0.2842 - val_acc: 0.8849\n",
      "Epoch 29/50\n",
      "201/200 [==============================] - 8s 40ms/step - loss: 0.2084 - acc: 0.9155 - val_loss: 0.3226 - val_acc: 0.8785\n",
      "Epoch 30/50\n",
      "201/200 [==============================] - 8s 39ms/step - loss: 0.2049 - acc: 0.9156 - val_loss: 0.3212 - val_acc: 0.8785\n",
      "Epoch 31/50\n",
      "201/200 [==============================] - 8s 39ms/step - loss: 0.2093 - acc: 0.9141 - val_loss: 0.2265 - val_acc: 0.9033\n",
      "Epoch 32/50\n",
      "201/200 [==============================] - 8s 39ms/step - loss: 0.1967 - acc: 0.9207 - val_loss: 0.2358 - val_acc: 0.9014\n",
      "Epoch 33/50\n",
      "201/200 [==============================] - 8s 39ms/step - loss: 0.1900 - acc: 0.9231 - val_loss: 0.2253 - val_acc: 0.9065\n",
      "Epoch 34/50\n",
      "201/200 [==============================] - 8s 42ms/step - loss: 0.1950 - acc: 0.9168 - val_loss: 0.2016 - val_acc: 0.9173\n",
      "Epoch 35/50\n",
      "201/200 [==============================] - 8s 38ms/step - loss: 0.1929 - acc: 0.9175 - val_loss: 0.2651 - val_acc: 0.8963\n",
      "Epoch 36/50\n",
      "201/200 [==============================] - 8s 38ms/step - loss: 0.1924 - acc: 0.9220 - val_loss: 0.2400 - val_acc: 0.9065\n",
      "Epoch 37/50\n",
      "201/200 [==============================] - 8s 38ms/step - loss: 0.1822 - acc: 0.9217 - val_loss: 0.2972 - val_acc: 0.8651\n",
      "Epoch 38/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "201/200 [==============================] - 8s 38ms/step - loss: 0.1864 - acc: 0.9219 - val_loss: 0.2381 - val_acc: 0.9071\n",
      "Epoch 39/50\n",
      "201/200 [==============================] - 8s 41ms/step - loss: 0.1815 - acc: 0.9253 - val_loss: 0.2001 - val_acc: 0.9173\n",
      "Epoch 40/50\n",
      "201/200 [==============================] - 8s 38ms/step - loss: 0.1848 - acc: 0.9257 - val_loss: 0.2489 - val_acc: 0.8919\n",
      "Epoch 41/50\n",
      "201/200 [==============================] - 8s 38ms/step - loss: 0.1750 - acc: 0.9303 - val_loss: 0.2851 - val_acc: 0.8836\n",
      "Epoch 42/50\n",
      "201/200 [==============================] - 8s 38ms/step - loss: 0.1699 - acc: 0.9284 - val_loss: 0.2538 - val_acc: 0.9059\n",
      "Epoch 43/50\n",
      "201/200 [==============================] - 8s 38ms/step - loss: 0.1799 - acc: 0.9246 - val_loss: 0.2229 - val_acc: 0.8995\n",
      "Epoch 44/50\n",
      "201/200 [==============================] - 8s 38ms/step - loss: 0.1644 - acc: 0.9299 - val_loss: 0.3845 - val_acc: 0.8670\n",
      "Epoch 45/50\n",
      "201/200 [==============================] - 8s 38ms/step - loss: 0.1761 - acc: 0.9255 - val_loss: 0.2823 - val_acc: 0.8772\n",
      "Epoch 46/50\n",
      "201/200 [==============================] - 8s 38ms/step - loss: 0.1614 - acc: 0.9359 - val_loss: 0.4470 - val_acc: 0.7990\n",
      "Epoch 47/50\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.1763 - acc: 0.9289\n",
      "Epoch 00047: reducing learning rate to 0.00010000000474974513.\n",
      "201/200 [==============================] - 8s 39ms/step - loss: 0.1755 - acc: 0.9295 - val_loss: 0.2283 - val_acc: 0.9084\n",
      "Epoch 48/50\n",
      "201/200 [==============================] - 8s 41ms/step - loss: 0.1421 - acc: 0.9455 - val_loss: 0.1494 - val_acc: 0.9421\n",
      "Epoch 49/50\n",
      "201/200 [==============================] - 8s 41ms/step - loss: 0.1278 - acc: 0.9501 - val_loss: 0.1399 - val_acc: 0.9427\n",
      "Epoch 50/50\n",
      "201/200 [==============================] - 8s 38ms/step - loss: 0.1367 - acc: 0.9455 - val_loss: 0.1464 - val_acc: 0.9434\n"
     ]
    }
   ],
   "source": [
    "# Create the model and compile\n",
    "model = create_model()\n",
    "\n",
    "history = model.fit_generator(gen_train_flow, \n",
    "                               validation_data=gen_valid_flow, \n",
    "                               steps_per_epoch=len(X_images) / batch_size, \n",
    "                               epochs=50,validation_steps=50, \n",
    "                               #callbacks=[ModelCheckpoint(file_path, save_best_only=True)])\n",
    "                               callbacks = callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-22T20:55:24.491079Z",
     "start_time": "2017-12-22T20:55:24.292081Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEICAYAAACktLTqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nmLgbhmEUICbuhmEYBYiJu2EYRgHy/8jsxSYbEZ5LAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x27c185274a8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEICAYAAABYoZ8gAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x27c2d7046d8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-22T20:38:57.257968Z",
     "start_time": "2017-12-22T20:38:56.290309Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1604/1604 [==============================] - 1s 455us/step\n",
      "Test loss: 0.176434441175\n",
      "Test accuracy: 0.93578553616\n"
     ]
    }
   ],
   "source": [
    "#Baseline CNN\n",
    "gmodel.load_weights(filepath=file_path)\n",
    "score = gmodel.evaluate(X_valid, y_valid, verbose=1)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-23T23:20:30.894574Z",
     "start_time": "2017-12-23T23:20:23.939506Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lambda_2 (Lambda)            (None, 75, 75, 3)         0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_6 (ZeroPaddin (None, 77, 77, 3)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 75, 75, 32)        896       \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 75, 75, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 37, 37, 32)        0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_7 (ZeroPaddin (None, 39, 39, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 37, 37, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 37, 37, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 18, 18, 64)        0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_8 (ZeroPaddin (None, 20, 20, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 18, 18, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 18, 18, 128)       512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 9, 9, 128)         0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_9 (ZeroPaddin (None, 11, 11, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 9, 9, 128)         147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 9, 9, 128)         512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_10 (ZeroPaddi (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 4, 4, 2)           2306      \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_2 ( (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 3         \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 244,549\n",
      "Trainable params: 243,845\n",
      "Non-trainable params: 704\n",
      "_________________________________________________________________\n",
      "1604/1604 [==============================] - 6s 3ms/step\n",
      "Test loss: 0.118484003009\n",
      "Test accuracy: 0.955735660848\n"
     ]
    }
   ],
   "source": [
    "#FCN\n",
    "\n",
    "model = create_model()\n",
    "\n",
    "model.load_weights(filepath=file_path)\n",
    "score = model.evaluate(X_valid, y_valid, verbose=1)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-22T20:57:01.398678Z",
     "start_time": "2017-12-22T20:56:50.820286Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Denoising and reshaping\n",
      "RGB done\n"
     ]
    }
   ],
   "source": [
    "_, X_test_b, X_test_images = create_dataset(test, False)\n",
    "#X_test_images = augment(X_test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-22T20:58:11.682754Z",
     "start_time": "2017-12-22T20:58:08.076986Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8424/8424 [==============================] - 4s 423us/step\n"
     ]
    }
   ],
   "source": [
    "predicted_test=gmodel.predict_proba(X_test_images)\n",
    "submission = pd.DataFrame()\n",
    "submission['id']=test['id']\n",
    "submission['is_iceberg']=predicted_test.reshape((predicted_test.shape[0]))\n",
    "submission.to_csv('Baseline2_CNN.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-22T20:58:18.301164Z",
     "start_time": "2017-12-22T20:58:15.436981Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8424/8424 [==============================] - 3s 335us/step\n"
     ]
    }
   ],
   "source": [
    "model = create_model()\n",
    "\n",
    "predicted_test=model.predict_proba(X_test_images)\n",
    "submission = pd.DataFrame()\n",
    "submission['id']=test['id']\n",
    "submission['is_iceberg']=predicted_test.reshape((predicted_test.shape[0]))\n",
    "submission.to_csv('FCN.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-24T16:52:22.644870Z",
     "start_time": "2017-12-24T16:52:04.680180Z"
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-834f77076372>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0msess\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m#sess.close()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_closed\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_opened\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\software\\anaconda\\lib\\site-packages\\tensorflow\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;31m# pylint: disable=wildcard-import\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[1;31m# pylint: enable=wildcard-import\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\software\\anaconda\\lib\\site-packages\\tensorflow\\python\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 83\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimator\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mestimator_lib\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mestimator\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_column\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfeature_column_lib\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfeature_column\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlayers\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\software\\anaconda\\lib\\site-packages\\tensorflow\\python\\estimator\\estimator_lib.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexporter\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mFinalExporter\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexporter\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLatestExporter\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_fn\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mEstimatorSpec\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_fn\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\software\\anaconda\\lib\\site-packages\\tensorflow\\python\\estimator\\inputs\\inputs.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;31m# pylint: disable=unused-import,line-too-long\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy_io\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy_input_fn\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpandas_io\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas_input_fn\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\software\\anaconda\\lib\\site-packages\\tensorflow\\python\\estimator\\inputs\\numpy_io.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcollections\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mqueues\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfeeding_functions\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;31m# Key name to pack the target into dict of `features`. See\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\software\\anaconda\\lib\\site-packages\\tensorflow\\python\\estimator\\inputs\\queues\\feeding_functions.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m   \u001b[1;31m# pylint: disable=g-import-not-at-top\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m   \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m   \u001b[0mHAS_PANDAS\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;32mexcept\u001b[0m \u001b[0mIOError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\software\\anaconda\\lib\\site-packages\\pandas\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig_init\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapi\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     43\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msparse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapi\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstats\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapi\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\software\\anaconda\\lib\\site-packages\\pandas\\core\\api.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0malgorithms\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfactorize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0munique\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue_counts\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissing\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0misnull\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnotnull\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcategorical\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mCategorical\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroupby\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mGrouper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformats\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mset_eng_float_format\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\software\\anaconda\\lib\\site-packages\\pandas\\core\\categorical.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0malgorithms\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfactorize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtake_1d\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0munique1d\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m from pandas.core.base import (PandasObject, PandasDelegate,\n\u001b[0m\u001b[0;32m     33\u001b[0m                               NoNewAttributesMixin, _shared_docs)\n\u001b[0;32m     34\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommon\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\software\\anaconda\\lib\\site-packages\\pandas\\core\\base.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcommon\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnanops\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnanops\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_libs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlib\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mlib\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfunction\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnv\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\software\\anaconda\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "\u001b[1;32mE:\\software\\anaconda\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "\u001b[1;32mE:\\software\\anaconda\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_load_unlocked\u001b[1;34m(spec)\u001b[0m\n",
      "\u001b[1;32mE:\\software\\anaconda\\lib\\importlib\\_bootstrap_external.py\u001b[0m in \u001b[0;36mexec_module\u001b[1;34m(self, module)\u001b[0m\n",
      "\u001b[1;32mE:\\software\\anaconda\\lib\\importlib\\_bootstrap_external.py\u001b[0m in \u001b[0;36mget_code\u001b[1;34m(self, fullname)\u001b[0m\n",
      "\u001b[1;32mE:\\software\\anaconda\\lib\\importlib\\_bootstrap_external.py\u001b[0m in \u001b[0;36mget_data\u001b[1;34m(self, path)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "sess = tf.Session()\n",
    "sess.close()\n",
    "sess._closed\n",
    "sess._opened"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
